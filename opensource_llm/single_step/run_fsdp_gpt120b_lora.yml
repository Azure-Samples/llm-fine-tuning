$schema: https://azuremlschemas.azureedge.net/latest/commandJob.schema.json  
type: command  
description: gpt-oss-lora-multigpu 
display_name: gpt-oss-lora-multigpu  
  
code: ./ # Path to your training script and related files  
inputs:
  model_dir: 
    path: azureml://registries/azureml-openai-oss/models/gpt-oss-120b/versions/4
command: >  
  accelerate launch 
  train_gpt_oss.py
  --seed 100  
  --model_name_or_path ${{inputs.model_dir}}  
  --dataset_name "smangrul/ultrachat-10k-chatml"  
  --chat_template_format "chatml"  
  --add_special_tokens False  
  --append_concat_token False  
  --splits "train,test"  
  --max_seq_length 1024  
  --num_train_epochs 1 
  --max_steps 20 
  --logging_steps 5  
  --log_level "info"  
  --logging_strategy "steps"  
  --eval_strategy "epoch"  
  --save_strategy "epoch"  
  --bf16 True  
  --packing True  
  --learning_rate 1e-4  
  --lr_scheduler_type "cosine"  
  --weight_decay 1e-4  
  --warmup_ratio 0.0  
  --max_grad_norm 1.0  
  --output_dir ${{outputs.output_dir}}
  --per_device_train_batch_size 1  
  --per_device_eval_batch_size 1 
  --gradient_accumulation_steps 16  
  --gradient_checkpointing False  
  --use_reentrant False  
  --dataset_text_field "content"  
  --use_peft_lora True  
  --lora_r 4  
  --lora_alpha 8  
  --lora_dropout 0.0 
  --lora_target_modules "all-linear"
  # --lora_target_parameters "12.mlp.experts.gate_up_proj,12.mlp.experts.down_proj,24.mlp.experts.gate_up_proj,24.mlp.experts.down_proj"
  --use_flash_attn True  
environment:  
  build:
    path: ./docker-context
compute: azureml:nc40h100  # Replace with your compute cluster name 
resources:  
  instance_count: 1 # Number of nodes  
experiment_name: gpt-oss-sft-training  
outputs:  
  output_dir:  
    type: uri_folder
    mode: rw_mount
