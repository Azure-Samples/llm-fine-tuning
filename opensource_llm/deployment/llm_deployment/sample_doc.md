**MASTER SERVICE AGREEMENT**    
(**AI / LLM Hosting**)    
  
**Effective Date:** [Date]    
  
**Parties:**    
[Client Name], a [Entity Type] organized and existing under the laws of [Jurisdiction], with a principal place of business at [Address] (“**Client**”), and    
[Service Provider Name], a [Entity Type] organized and existing under the laws of [Jurisdiction], with a principal place of business at [Address] (“**Service Provider**”).    
  
---  
  
### RECITALS    
WHEREAS, the Client desires to engage the Service Provider to host, operate, and maintain large language models (LLMs) with a high degree of reliability, scalability, and performance;    
  
WHEREAS, the Service Provider possesses expertise in scalable AI inference infrastructure, including but not limited to the use of vLLM, Ray Serve, Triton, and TensorRT‑LLM, and has the capability to provide such services in compliance with applicable laws and industry standards;    
  
NOW, THEREFORE, in consideration of the mutual promises and covenants herein contained, the Parties agree as follows:    
  
---  
  
### 1. DEFINITIONS    
For purposes of this Agreement, the following terms shall have the meanings set forth below:    
  
1.1 **LLM**: A transformer‑based large language model (e.g., GPT, LLaMA) capable of natural language understanding and generation.    
1.2 **Inference Request**: An application programming interface (API) call made to an LLM for the purpose of obtaining a model-generated output.    
1.3 **Token**: A discrete unit of text, word piece, or sub‑word element processed or generated by an LLM during inference or training.    
1.4 **Service Levels**: The agreed‑upon performance and availability metrics described in **Exhibit D**.    
1.5 **Downtime**: A period during which the API is unavailable to process valid inference requests, excluding scheduled maintenance windows.    
1.6 **Change Order**: A mutually agreed modification to the Services, deliverables, or scope, documented in writing in accordance with **Exhibit H**.    
1.7 **Incident**: Any unplanned interruption, service degradation, or system malfunction impacting the delivery of Services.    
1.8 **Personal Data**: Any data relating to an identified or identifiable natural person, as defined under applicable Data Protection Laws.    
1.9 **Data Protection Laws**: All applicable privacy and data protection laws and regulations, including but not limited to the GDPR, CCPA, and LGPD.    
1.10 **Ethical Guidelines**: The policies and restrictions set forth in **Exhibit E**, which govern the lawful and ethical use of the Services.    
  
---  
  
### 2. SCOPE OF SERVICES    
The Service Provider shall perform the following core functions:    
  
- Host LLMs on GPU‑accelerated infrastructure designed for high throughput and low latency.    
- Scale workloads dynamically through vLLM, Ray Serve, and Triton inference serving frameworks.    
- Provide secure and documented APIs for inference, fine‑tuning, and embeddings generation.    
- Continuously monitor system performance, detect anomalies, and respond promptly to incidents.    
- Ensure ongoing compliance with all applicable laws, regulations, and the Ethical Guidelines.    
  
Optional services, including model fine‑tuning, custom embeddings, and multi‑model routing, are available upon mutual agreement and may incur additional fees as outlined in **Exhibit B**.    
  
---  
  
### 3. TERM    
The initial term of this Agreement shall be **three (3) years** from the Effective Date. Thereafter, this Agreement shall automatically renew for successive one‑year periods unless either Party provides written notice of non‑renewal at least ninety (90) days prior to the expiration of the then‑current term.    
  
---  
  
### 4. FEES & PAYMENT    
All fees are set forth in **Exhibit B** and include a base hosting fee, per‑token usage fees, and charges for optional services. Invoices shall be issued monthly and are payable within thirty (30) days of receipt. Late payments shall accrue interest at the rate specified in Exhibit B.    
  
---  
  
### 5. CLIENT RESPONSIBILITIES    
The Client shall:    
  
- Provide only lawful and non‑infringing training or input data.    
- Comply with the Ethical Guidelines at all times.    
- Ensure it possesses all necessary rights, licenses, and consents to use any data supplied to the Service Provider.    
  
---  
  
### 6. CONFIDENTIALITY    
Both Parties agree to maintain the confidentiality of proprietary information, including but not limited to model weights, datasets, and API logs, and to use such information solely for the purposes of fulfilling this Agreement.    
  
---  
  
### 7. DATA PROTECTION ADDENDUM    
The Parties agree to the data protection obligations set forth in **Exhibit F**, including but not limited to compliance with GDPR Article 28, maintenance of a current subprocessor list, honoring data subject rights, providing breach notifications within forty‑eight (48) hours, encrypting data using AES‑256 at rest and TLS 1.3 in transit, and limiting log retention to ninety (90) days.    
  
---  
  
### 8. INTELLECTUAL PROPERTY    
Unless otherwise agreed in writing, the Client shall retain ownership of the hosted models, while the Service Provider shall retain ownership of its orchestration scripts, configurations, and tooling.    
  
---  
  
### 9. WARRANTIES & SERVICE LEVELS    
The Service Provider warrants that it will meet the following minimum service levels: 99.9% uptime, median latency of less than 500ms for prompts of up to 512 tokens, and a priority‑one incident response time of fifteen (15) minutes or less.    
  
---  
  
### 10. INCIDENT MANAGEMENT    
Incident handling procedures, severity classifications, and response/resolution targets are detailed in **Exhibit G**.    
  
---  
  
### 11. AUDIT RIGHTS    
The Client may conduct one (1) audit per calendar year to verify the Service Provider’s compliance with this Agreement. The Service Provider shall cooperate and provide relevant documentation.    
  
---  
  
### 12. CHANGE ORDERS    
Any changes to the architecture, hosting environment, or APIs shall be documented and implemented in accordance with the process in **Exhibit H**.    
  
---  
  
### 13. TERMINATION    
Either Party may terminate this Agreement for convenience or for cause, subject to any applicable notice requirements. Upon termination, the Service Provider shall provide the Client with all model weights, configurations, and relevant documentation necessary to continue operations.    
  
---  
  
### 14. FORCE MAJEURE    
Neither Party shall be liable for delays or failures due to causes beyond its reasonable control, including but not limited to natural disasters, acts of government, labor disputes, or GPU supply chain disruptions.    
  
---  
  
### 15. GOVERNING LAW & DISPUTE RESOLUTION    
This Agreement shall be governed by and construed in accordance with the laws of [Jurisdiction]. Any disputes shall be resolved by binding arbitration in [Location] under the rules of [Rules].    
  
---  
  
### 16. MISCELLANEOUS    
This Agreement constitutes the entire agreement between the Parties with respect to its subject matter. No amendment shall be effective unless in writing and signed by both Parties. Neither Party may assign this Agreement without prior written consent, except in connection with a merger or sale of substantially all assets. If any provision is found invalid, the remaining provisions shall remain in force. Notices shall be delivered to the addresses set forth above.    
  
---  
  
**EXHIBITS**    
*(Expanded descriptions remain attached: A – Scope of Services, B – Fees & Payment, C – Intellectual Property, D – SLA, E – Ethical Guidelines, F – Data Processing Addendum, G – Incident Management, H – Change Orders)*    
  
---  
  
**Signatures:**    
  
____________________ (Client)    
Name:    
Title:    
Date:    
  
____________________ (Service Provider)    
Name:    
Title:    
Date:  